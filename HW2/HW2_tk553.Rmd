# Part 1


```{r}
spam_test <- read.csv("~/ProgramZ/stat365/HW2/spam_test.csv")
spam_train <- read.csv("~/ProgramZ/stat365/HW2/spam_train.csv")
require(FNN)
```

Get the column with the na values in both test and train set. Also get response variable column.

```{r}
nacol_name <- "capital_run_length_average"
nacol_test <- which(colnames(spam_test)==nacol_name)
col_resp <- which(colnames(spam_train)=="spam")
nacol_train <- which(colnames(spam_train)==nacol_name)
```

Scale both test and train data, and remove the response variable.

```{r}
scale_test <- spam_test
scale_train <- spam_train
scale_test[,-nacol_test] <- as.data.frame(scale(scale_test[,-nacol_test]))
scale_train[,-c(nacol_train,col_resp)] <- as.data.frame(scale(scale_train[,-c(nacol_train,col_resp)]))
scale_train$spam <-NULL
```


Get row in test for which there are na values, run knn and replace the na values in original dataset

```{r}
na_r <- which(is.na(spam_test$capital_run_length_average))
test <- FNN::knn.reg(scale_test[-na_r,-nacol_test],test=scale_test[na_r,-nacol_test],y=scale_test[-na_r,nacol_test],k=15)
spam_test[na_r,nacol_test] <- test$pred
```

Do the same for train

```{r}
na_r2 <- which(is.na(spam_train$capital_run_length_average))
train <- FNN::knn.reg(scale_train[-na_r2,-nacol_train],test=scale_train[na_r2,-nacol_train],y=scale_train[-na_r2,nacol_train],k=15)
spam_train[na_r2,nacol_train] <- train$pred
```

# Part 2

Comments are within the function.

```{r}
knnclass <- function(xtrain, xtest, ytrain) {

  #standardize training and test using training set only
  trainMeans <- apply(xtrain, 2, function(y) mean(y))
  trainSD <- apply(xtrain, 2, function(y) sd(y))
  xtest <- (xtest-as.list(trainMeans))/as.list(trainSD)
  xtrain <- (xtrain-as.list(trainMeans))/as.list(trainSD)

  #split training into training and validation
  #set.seed(123)
  ntrain <- nrow(xtrain)
  s <- sample(1:ntrain, (4*ntrain)/5, replace = FALSE)
  trainSet <- xtrain[s,]
  trainY <- ytrain[s]
  valSet <- xtrain[-s,]
  valY <- ytrain[-s]
  testSet <- xtest

  #function that calculates euc dist to each row in test. Used in the function below
  euc.dist <- function(testrow,traindata) {
    sum <- apply(((as.list(testrow)-traindata)^2),1,sum)
    return(sqrt(sum))
  }
  
  #function that gets the distance matrix for ONE row in test to all rows in train
  getDistMatrix <- function(xtestrow,xtrain) {
    eucDist<-as.vector(euc.dist(xtestrow,xtrain))
    numberedRows <- c(1:nrow(xtrain))
    eucDistDF <- data.frame(numberedRows,eucDist)
    sortDistDF <- eucDistDF[order(eucDistDF$eucDist),]
    return(sortDistDF)
  }
  
  #Sorted distance list containing distance matrix for each test row. Only need to do this once, each calculation from k=2 to 15 will use the same matrix. test set is the validation set.
  sortDistDFV <- apply(valSet,1,getDistMatrix,xtrain=trainSet)

  #function that gets the classification for each testrow
  getClassfn <- function(kDistDF, y) {
    kYClass <- y[kDistDF[,1]]
    class <- as(names(which.max(table(kYClass))), Class=mode(y))
    return(class)
  }
  
  #classification
  kclass <- function(sortDistDFV,y,k) {
    get.predic <- function(sortDistDF,y,k) {
      sortDistDF <- (sortDistDF)
      kDistDF <- sortDistDF[1:k,]
      class <- getClassfn(kDistDF,y)
      return (class)
    }
    #lapply because sortDistDFV is a list. (apply returns list).
    predicted <- lapply(sortDistDFV,get.predic,y=y,k=k)
    predicted <- (as.vector(unlist(predicted)))
    return (predicted)
  }
  
  #function to calculate misclassfication error rate
  mer <- function(pred,actual) {
    matchv <- mapply(function(x,y) {ifelse ((x==y),0,1)}, pred, actual,SIMPLIFY=TRUE)
    return(sum(matchv)/length(pred))
  }
  
  #We get the misclassfication error rate for each k 2:15. 
  nK <- 15
  kCount <- c(2:nK)
  kDF <- data.frame(kCount,rep(NA,nK-1))
  colnames(kDF) <- c("K","MER")
  for (i in 2:nK) {
    pred <- kclass(sortDistDFV,y=trainY,k=i)
    e <- mer(pred,valY)
    kDF$MER[i-1] <- e
  }
  kDF <- kDF[order(kDF$MER),]
  
  #optimal k is the one with lowest MER, first item in the ordered vector.
  optK <- kDF$K[1]
  #Now get the distance matrix list for the actual test set. 
  sortDistDFV_final <- apply(testSet,1,getDistMatrix,xtrain=xtrain)
  finalPred <- kclass(sortDistDFV_final,ytrain,optK)
}

```

# Part 3

(cont'd from part 1): We have set up variables such that the UNSCALED train and test data WITH filled in N/A values are called spam_train and spam_test respectively.

```{r}
spam <- spam_train$spam
```

## First part (KNN without capital run ave length)

```{r}
spam_train_first <- spam_train
spam_test_first <- spam_test
spam_train_first$spam <- NULL
#get rid of captital_run_length_average predictor
spam_train_first$capital_run_length_average <- NULL
spam_test_first$capital_run_length_average <- NULL
knn_pred1 <- knnclass(spam_train_first,spam_test_first,spam)
```

## Second part (KNN with capital run ave length)

```{r}
spam_train_second <- spam_train
spam_test_second <- spam_test
spam_train_second$spam <- NULL
knn_pred2 <- knnclass(spam_train_second,spam_test_second,spam)
#if k = 15, this is the "model" answer, w/o scaling
#knn_pred22 <- as.vector(FNN::knn(spam_train_second,spam_test_second,as.factor(spam), k=15))
```

## Third part (Logistic regression without capital run length ave) 

```{r}
spam_train_third <- spam_train
spam_test_third <- spam_test
spam_train_third$capital_run_length_average <- NULL
spam_test_third$capital_run_length_average <- NULL
m3 <- glm(spam~.,family=binomial,data=spam_train_third)
logm_pred1 <- predict(m3, newdata=spam_test_third, type="response")
```

## Fourth part (Logistic regression with capital run length ave)

```{r}
spam_train_fourth <- spam_train
spam_test_fourth <- spam_test
m4 <- glm(spam~.,family=binomial,data=spam_train_fourth)
logm_pred2 <- predict(m4, newdata=spam_test_fourth, type="response")
```

Let's take a look at the summary of the 4th model. In 3-4 sentences, provide a quick summary of your second logistic regression model. Which predictors appeared to be most significant? Are there any surprises in the predictors that ended up being significant or not significant?

```{r}
summary(m4)
```

The residual deviance (1295.2) is lower than the null deviance (4316.6)-- this is a good sign that some of the predicors are significant. Capital_run_length_longest, word_freq_edu, word_freq_george, word_freq_money word_freq_free are some of the significant predictors for this model. Somewhat surprising that word_freq_george would be so significant-- are there a lot of people named george?

This is data frame that is the .csv file

```{r}
HW2_tk553_results <- data.frame(spam_test$capital_run_length_average,knn_pred1,knn_pred2,logm_pred1,logm_pred2)
#write.csv with row.names=FALSE
```
